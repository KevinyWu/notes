{
  "main": {
    "id": "8e8ee6d543c6a1b0",
    "type": "split",
    "children": [
      {
        "id": "f0364015e54aada1",
        "type": "tabs",
        "children": [
          {
            "id": "bc110d41efd2ee9c",
            "type": "leaf",
            "state": {
              "type": "markdown",
              "state": {
                "file": "personal-notes/phd/professors/Dinesh Jayaraman.md",
                "mode": "source",
                "source": false
              },
              "icon": "lucide-file",
              "title": "Dinesh Jayaraman"
            }
          },
          {
            "id": "a8d9b0eb839489a6",
            "type": "leaf",
            "state": {
              "type": "markdown",
              "state": {
                "file": "personal-notes/phd/Interview.md",
                "mode": "source",
                "source": false
              },
              "icon": "lucide-file",
              "title": "Interview"
            }
          },
          {
            "id": "c12d6f2d57365c2b",
            "type": "leaf",
            "state": {
              "type": "markdown",
              "state": {
                "file": "personal-notes/phd/Ideas.md",
                "mode": "source",
                "source": false
              },
              "icon": "lucide-file",
              "title": "Ideas"
            }
          },
          {
            "id": "b2ac5e1e578680ff",
            "type": "leaf",
            "state": {
              "type": "markdown",
              "state": {
                "file": "papers/reinforcement-learning/Rank2Reward - Learning Shaped Reward Functions from Passive Video.md",
                "mode": "source",
                "source": false
              },
              "icon": "lucide-file",
              "title": "Rank2Reward - Learning Shaped Reward Functions from Passive Video"
            }
          },
          {
            "id": "cce48cb3cdae7b7d",
            "type": "leaf",
            "state": {
              "type": "markdown",
              "state": {
                "file": "papers/visual-representations/VIP - Towards Universal Visual Reward and Representation via Value-Implicit Pre-Training.md",
                "mode": "source",
                "source": false
              },
              "icon": "lucide-file",
              "title": "VIP - Towards Universal Visual Reward and Representation via Value-Implicit Pre-Training"
            }
          }
        ]
      }
    ],
    "direction": "vertical"
  },
  "left": {
    "id": "5ef6b1eaae213ccb",
    "type": "split",
    "children": [
      {
        "id": "ea05bb374ea5e54b",
        "type": "tabs",
        "children": [
          {
            "id": "1ef5240235abf41d",
            "type": "leaf",
            "state": {
              "type": "file-explorer",
              "state": {
                "sortOrder": "alphabetical",
                "autoReveal": false
              },
              "icon": "lucide-folder-closed",
              "title": "Files"
            }
          },
          {
            "id": "55fbf35415eadeae",
            "type": "leaf",
            "state": {
              "type": "search",
              "state": {
                "query": "andre",
                "matchingCase": false,
                "explainSearch": false,
                "collapseAll": false,
                "extraContext": false,
                "sortOrder": "alphabetical"
              },
              "icon": "lucide-search",
              "title": "Search"
            }
          },
          {
            "id": "32cfa6a8c99d8a79",
            "type": "leaf",
            "state": {
              "type": "bookmarks",
              "state": {},
              "icon": "lucide-bookmark",
              "title": "Bookmarks"
            }
          }
        ]
      }
    ],
    "direction": "horizontal",
    "width": 220.5,
    "collapsed": true
  },
  "right": {
    "id": "db81aa8145141e1b",
    "type": "split",
    "children": [
      {
        "id": "5ad7545fbb2b4813",
        "type": "tabs",
        "children": [
          {
            "id": "ac568914f5bfac5b",
            "type": "leaf",
            "state": {
              "type": "backlink",
              "state": {
                "collapseAll": false,
                "extraContext": false,
                "sortOrder": "alphabetical",
                "showSearch": false,
                "searchQuery": "",
                "backlinkCollapsed": false,
                "unlinkedCollapsed": true
              },
              "icon": "links-coming-in",
              "title": "Backlinks"
            }
          },
          {
            "id": "eaec31c2909b7aa2",
            "type": "leaf",
            "state": {
              "type": "outgoing-link",
              "state": {
                "linksCollapsed": false,
                "unlinkedCollapsed": true
              },
              "icon": "links-going-out",
              "title": "Outgoing links"
            }
          },
          {
            "id": "206a8edcdff6b52d",
            "type": "leaf",
            "state": {
              "type": "tag",
              "state": {
                "sortOrder": "frequency",
                "useHierarchy": true
              },
              "icon": "lucide-tags",
              "title": "Tags"
            }
          },
          {
            "id": "d2303f1450c8793d",
            "type": "leaf",
            "state": {
              "type": "outline",
              "state": {},
              "icon": "lucide-list",
              "title": "Outline"
            }
          }
        ]
      }
    ],
    "direction": "horizontal",
    "width": 300,
    "collapsed": true
  },
  "left-ribbon": {
    "hiddenItems": {
      "switcher:Open quick switcher": false,
      "graph:Open graph view": false,
      "canvas:Create new canvas": false,
      "daily-notes:Open today's daily note": false,
      "templates:Insert template": false,
      "command-palette:Open command palette": false,
      "table-editor-obsidian:Advanced Tables Toolbar": false,
      "pdf-plus:PDF++: Toggle auto-copy": false,
      "pdf-plus:PDF++: Toggle auto-focus": false,
      "pdf-plus:PDF++: Toggle auto-paste": false
    }
  },
  "active": "bc110d41efd2ee9c",
  "lastOpenFiles": [
    "papers/visual-representations/VIP - Towards Universal Visual Reward and Representation via Value-Implicit Pre-Training.md",
    "papers/reinforcement-learning/Rank2Reward - Learning Shaped Reward Functions from Passive Video.md",
    "personal-notes/phd/Ideas.md",
    "personal-notes/phd/Interview.md",
    "personal-notes/phd/professors/Dinesh Jayaraman.md",
    "personal-notes/phd/Applications.md",
    "personal-notes/phd/professors/Serena Booth.md",
    "personal-notes/phd/professors/Yogesh Girdhar.md",
    "personal-notes/phd/professors/Rachel Holladay.md",
    "personal-notes/phd/professors/Antonio Loquercio.md",
    "personal-notes/learning/Learning.md",
    "papers/reinforcement-learning/Mastering Visual Continuous Control - Improved Data-Augmented Reinforcement Learning.md",
    "papers/reinforcement-learning/Interactively shaping agents via human reinforcement - The TAMER framework.md",
    "Untitled.md",
    "personal-notes/phd/professors/Andreea Bobu.md",
    "papers/reinforcement-learning/README.md",
    "papers/reinforcement-learning/img/tamer_algorithm_credit.png",
    "papers/reinforcement-learning/img/tamer_algorithm.png",
    "papers/reinforcement-learning/img/tamer.png",
    "papers/reinforcement-learning/Playing Atari with Deep Reinforcement Learning.md",
    "README.md",
    "papers/reinforcement-learning/Learning Reward Functions for Robotic Manipulation by Observing Humans.md",
    "papers/reinforcement-learning/Diffusion Reward - Learning Rewards via Conditional Video Diffusion.md",
    "personal-notes/learning/Quick Notes.md",
    "talks/Rachel Holladay - Leveraging Mechanics for Multi-step Robotic Manipulation Planning.md",
    "personal-notes/research/Exploration.md",
    "personal-notes/phd/professors/Yunzhu Li.md",
    "personal-notes/phd/professors/Yilun Du.md",
    "talks/Yilun Du - Generalizing Outside The Data Distribution through Compositional Generation.md"
  ]
}