{"path":"appendix/figures/simclr.png","text":"Maximize agreement Zie— = 2z o] T96) h; <— Representation — h; f0O) f0) IR e T T Figure 2. A simple framework for contrastive learning of visual representations. Two separate data augmentation operators are sampled from the same family of augmentations (¢ ~ 7 and t' ~ T) and applied to each data example to obtain two correlated views. A base encoder network f(-) and a projection head g(-) are trained to maximize agreement using a contrastive loss. After training is completed, we throw away the projection head g(-) and use encoder f(-) and representation h for downstream tasks.","libVersion":"0.3.2","langs":"eng"}