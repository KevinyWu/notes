# Denoising Diffusion Probabilistic Models

**Authors**: Jonathan Ho, Ajay Jain, Pieter Abbeel

#diffusion

[[papers/generative-models/README#[2020-06] Denoising Diffusion Probabilistic Models|README]]

[Paper](http://arxiv.org/abs/2006.11239)
[Code](https://github.com/lucidrains/denoising-diffusion-pytorch)
[Website](https://calvinyluo.com/2022/08/26/diffusion-tutorial.html)
[Video](https://www.youtube.com/watch?v=W-O7AZNzbzQ)
[Blog](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/)
[Annotated Code](https://nn.labml.ai/diffusion/ddpm/index.html)

## Abstract

> We present high quality image synthesis results using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. Our best results are obtained by training on a weighted variational bound designed according to a novel connection between diffusion probabilistic models and denoising score matching with Langevin dynamics, and our models naturally admit a progressive lossy decompression scheme that can be interpreted as a generalization of autoregressive decoding. On the unconditional CIFAR10 dataset, we obtain an Inception score of 9.46 and a state-of-the-art FID score of 3.17. On 256x256 LSUN, we obtain sample quality similar to ProgressiveGAN. Our implementation is available at <https://github.com/hojonathanho/diffusion>

## Summary

- Notes from the introduction and conclusion sections

## Background

- Notes about the background information

## Method

- Notes about the method

## Results

- Notable results from the paper
